# 数值分析<3>——任意曲线拟合

## 全文目录

[（博客园）机器学习](https://www.cnblogs.com/WarrenRyan/p/12503734.html)

[（Github）MachineLearning Math](https://github.com/StevenEco/MachineLearning-Math)

## 万物皆是展开式

你是否想过这样一个问题，任何的函数，也许都能通过一个“大一统”理论将他们整合在一起。事实上对于任意一种对应关系，我们都能找到一个函数尽可能去贴合它，我们采取的是一种极限的思维，举个不恰当的例子来描述，如果一个东西看起来像牛粪，闻起来像牛粪，尝起来像牛粪，那么它就是牛粪。并且，更加一般的是，在一个微小的区间内，函数还可以写成一个幂函数的形式去大致的估算。

泰勒定理给了我们一个很通用的方法去研究函数：

设n是一个正整数。如果定义在一个包含a的区间上的函数$f$在a点处n+1次可导，那么对于这个区间上的任意x，都有：

$$
f(x)=\sum^{n}_{i=0}\frac{f^{(i)}(a)}{i!}(x-1)^i+R_n(x)
$$

其中，上式的$R_n(x)$是泰勒公式的估计余项，这在后续会进行详细的解释。

如果仅仅只是背下来，你就不能领略到泰勒展开的精妙之处了。我们用一些很精妙的手段，自然的推导出泰勒公式。首先我们先假定一个函数存在一阶导函数，来看一看一阶导数的定义

$$
\lim_{x\to x_0}\frac{f(x)-f(x_0)}{x-x_0}=f^{'}(x_0)
$$

其实从这里不难发现，导数定义上，给了我们一种当$x\to x_0$的时候，计算$f(x)$的手段，我们假定这个过程的无穷小为$\alpha(x)(x\to x_0)$，那么我们可以把这个等式改写为如下形式

$$
\lim_{x\to x_0} = f(x) = L \Leftrightarrow f(x) = L+\alpha(x)
\\
\\
\lim_{x\to x_0}f^{'}(x) = \frac{f(x)-f(x_0)}{x-x_0} = f^{'}(x)+\alpha(x)
\\
\\
f(x) = f(x_0)+f^{'}(x_0)(x-x_0)+\alpha(x)\times(x-x_0)
\\
\\
=f(x_0)+f^{'}(x_0)(x-x_0)+\omicron(x-x_0)
$$

### 余项估计

从上面的推导规程很明显可以看出最后一项无穷小是$(x-x_0)$的高阶无穷小，所以我们就很自然的得出了$f(x)$的一阶泰勒展开式。利用这个公式，我们可以去拟合任意可导的函数的任意函数点，再从点的绘制成函数曲线。

当然我们会认为，一阶导数所带来的那个余项无穷小是不够精确的，提高精确值的方法就是让这个无穷小的阶升高，那么我们可以继续考虑二阶展开，让这个无穷小的阶数升高。首先我们来单独的研究一下这个无穷小。

$$
\omicron(x-x_0) = f(x)-f(x_0)-f^{'}(x_0)(x-x_0)
\\
\\
\lim_{x\to x_0}\frac{\omicron(x-x_0)}{(x-x_0)^2} = \lim_{x\to x_0}\frac{f(x)-f(x_0)-f^{'}(x_0)(x-x_0)}{(x-x_0)^2}
$$

很明显，只要我们的函数二阶可导，那么上述式子就满足了0/0型的洛必达法则！那么我们直接开始洛必达！

$$
\lim_{x\to x_0}\frac{f(x)-f(x_0)-f^{'}(x_0)(x-x_0)}{(x-x_0)^2} = \lim_{x\to x_0}\frac{f^{'}(x)-f^{'}(x_0)}{2(x-x_0)}
\\
\\
=\frac{1}{2}f^{''}(x_0) = \lim_{x\to x_0}\frac{\omicron(x-x_0)}{(x-x_0)^2} \Leftrightarrow \omicron(x-x_0) = \frac{1}{2}f^{''}(x_0)(x-x_0)^2
\\
\\
\Leftrightarrow f(x) = f(x_0)+f^{'}(x_0)(x-x_0)+\frac{1}{2}f^{''}(x_0)(x-x_0)^2 +\omicron(x-x_0)^2
$$

这样，我们就得到了拥有二阶无穷小的泰勒公式！如法炮制，只要我们的$f(x)$在$x_0$满足n阶可导的情况，那么我们就可以一直用上面的方式得到n阶泰勒展开公式。

接下来我们来估计余项，也就是误差的大小。在上面的推断中，我们一直使用无穷小进行误差的估计，这种类型的余项叫做皮亚诺余项，这种好处是可以很直观的看出误差的阶数，但是并不算是一个特别容易计算的值，我们仅仅知道最大的误差不超过$\omicron(x-x_0)^n$。因此我们可以思考一下，假如我们展开到第n阶的时候，误差必然是比第n+1阶新引入的那一项更大，但比第n阶是更小的，那么我们可以用介值定理和拉格朗日微分中值定理进行推广，那么余项可以写成

$$
R_n(x) = \frac{f^{(n+1)}(\theta)}{n!}(x-x_0)^{n+1}
$$

利用泰勒公式，我们就可以将一个可导函数的任意点进行一个拟合，从而得到一个较为精确的结果，从函数图像上看，泰勒公式是一个级数累加不断前进逼近的过程。

## 多项式插值法

如果针对的是一个有穷数列，例如请你寻找以下数字的规律并填写接下来的数字

- 4、7、11、18、29、47、(__)

你的第一眼可能会发现这是一个类似 *Fibonacci数列*的规律数字，但实际上我们对于有穷离散型函数，也可以推出这样一个奇怪的对应关系

$$
a_x=\frac {28579 x^9}{90720} - \frac{142847 x^8}{10080} + \frac{4140931 x^7}{15120} \\- \frac{713627 x^6}{240} + \frac{17192243 x^5}{864} - \frac{40631363 x^4}{480} \\+ \frac{644406697 x^3}{2835} - \frac{927568429 x^2}{2520} +\frac {101426987 x}{315} - 113739
$$

并且对于任何的有穷的数列，我们总是能使用一个通项公式进行数据的拟合计算。如果我们把上述拓展到函数领域，也就是对于任意有限多的$(x_i,y_i)$，且这些点符合函数的规则，每个x对应唯一的y，我们总能用一个连续的多项式组合的函数，保证这个函数经过上面所有的点，而计算这个多项式的过程，我们就称为插值。插值是求值的逆过程，利用已有的点，反推出曲线的大致模样。

插值的思想和泰勒很类似，就是说如果观测误差足够小的时候，那么就认为它就是准确的值。我们给定的点符合$f(x_i)=y_i$，那么我们的插值构造函数就是$g(x_i)=y_i$。

通常我们采用累加的多项式进行插值计算，因为我们的计算都是建立在计算机之上，计算机对于特殊的运算是非常缓慢且复杂的，例如之前提到的泰勒展开，因此我们尽可能需要将计算变成四则运算，同时我们的插值函数还需要保证解的唯一性，因此我们通常将插值函数写成如下形式：

$$
P(x) = \sum_{i=0}^{n}a_{i}x^{i}
$$

利用多项式幂函数和作为插值函数的好处是，它是恒可微的，并不需要像泰勒展开一样，需要先确定可微分的函数才可以继续求解。同时至于这种方式的唯一性，我们可以做一个简单的推导。

假设给定了n+1个数据采样$(x_1,y_1),(x_2,y_2)\dotsb(x_{n+1},y_{n+1})$，根据插值法的规则，那么我们构造出的多项式必然满足下列方程组：

$$
\left\{\begin{matrix}
 p(x_0) = a_0+a_1x_0+a_2x_{0}^2+\dotsb+a_nx_{0}^n = y_0  \\
 p(x_1) = a_0+a_1x_1+a_2x_{1}^2+\dotsb+a_nx_{1}^n = y_1 \\
p(x_2) = a_0+a_1x_2+a_2x_{2}^2+\dotsb+a_nx_{2}^n = y_2\\
\vdots \\
p(x_n) = a_0+a_1x_n+a_2x_{n}^2+\dotsb+a_nx_{n}^n = y_n
\end{matrix}\right.
$$

如果熟悉线性代数，我们可以很清楚的发现这是一个非齐次线性方程组（a为未知数），我们可以得到该方程组的$Vandermonde$行列式

$$
P = VA=Y

\Leftrightarrow \begin{bmatrix}
 1 & x_0&x_{0}^{2} &\cdots & x_{0}^{n} \\
 1 & x_1&x_{1}^{2} &\cdots & x_{1}^{n}  \\
 \vdots&\vdots&\vdots&\vdots&\vdots\\
 1 & x_n&x_{n}^{2} &\cdots & x_{n}^{n}
\end{bmatrix}
\begin{bmatrix}
a_0\\
a_1\\
\vdots\\
a_n
\end{bmatrix}=
\begin{bmatrix}
y_0\\
y_1\\
\vdots\\
y_n
\end{bmatrix}
$$

故有

$$
\begin{vmatrix}V\end{vmatrix} = \begin{vmatrix}
 1 & x_0&x_{0}^{2} &\cdots & x_{0}^{n} \\
 1 & x_1&x_{1}^{2} &\cdots & x_{1}^{n}  \\
 \vdots&\vdots&\vdots&\vdots&\vdots\\
 1 & x_n&x_{n}^{2} &\cdots & x_{n}^{n}
\end{vmatrix} = \prod_{i=1}^{n}\prod_{j=0}^{n}(x_i-x_j)
$$

因为我们取得采样点都是不同的点，因此可以保证有$x_i \neq x_j$，那么根据$Cramer$法则，该$Vandermonde$行列式必有唯一解，从而保证了我们的插值函数是唯一的。不过多项式插值也不是全无缺点的，计算复杂度较高、在端点出容易出现龙格现象（一种函数值的剧烈振荡）。这些问题我们将在后面进行讨论。

### 拉格朗日插值法

拉格朗日插值是一种朴素拟合的手段，假设我们给定n个数据点$(x_1,y_1),(x_2,y_2)\dotsb(x_n,y_n)$，拉格朗日插值法，就是构造一条经过这些点的曲线（如果本身的数据就存在大量误差，则只需要靠近而不需经过），用这条线去模拟实际的曲线。这个方法和我们通过两点构造一条直线的方法有异曲同工之妙，当我们代入一个值$x_1$之后，所有不能得到$y_1$的多项式都将系数为0。

#### 一次线性插值

我们先从最容易的一次线性插值来入手，假设我们有曲线$f(x_i) = y_i$，取两个采样点$x(x_0,y_0),(x_1,y_1)$，我们一次线性插值则是使用一条直线来近似替代，那么我们需要构建一个函数，使得$p(x_0)=y_0,p(x_1)=y_1$，那么可以作出这样一条直线（直线对称式）：

$$
p(x) = \frac{x-x_0}{x_0-x_1}y_0+\frac{x - x_1}{x_1-x_0}y_1
$$

我们看一个简单的函数拟合，已知$y=\sqrt{x}$的两个采样点$(100,10),(121,11)$,求$\sqrt{115}$，我们利用线性插值法，可以计算出结果是10.7142，精确值为10.724，可见利用线性插值也具备三位有效数字。但是如果将值偏离采样点，例如我们需要计算$\sqrt{2}$，精确值为1.414，而插值法计算出的值为5.333，一位有效数字都没有。

实际上我们利用信息的角度去考虑，比如在警察办案过程中，往往会涉及到一个犯罪嫌疑人画像的制作，如果说目击者告诉警察的有效信息为：犯罪分子是一个高鼻梁，蓝眼睛。那么警察在绘制图像的时候，眼睛和鼻子或者周边的颧骨可能会相对精确不少，但是通过鼻子和眼睛的信息，你让警察去猜想他是否是秃顶或者升高体重，自然会不准确。所以这里面也涉及到了一部分信息熵的内容，因为信息过少而导致的数据不精确。

#### 拉格朗日插值

通过一次插值的实践过程和之前对于多项式插值的，我们知道采样点很少导致的信息缺失，那么我们就应该找到更多的采样点进行构造更好的多项式。

根据观察，其实我们可以思考一下，之前多项式插值法中，我们最终是需要通过行列式解出各个多项式的系数，那么我们假定为这样的插值函数

$$
p(x)=\sum_{i=0}^{n}l_i(x)y_i
$$

我们将多项式系数写为$l(x)$我们称为拉格朗日插值基函数。这个基函数必然满足

$$
p(x_i)=y_i \\
l_i(x_k) =\begin{cases}
 0,& k\neq i\\
 1,& k=0
\end{cases}
$$

通过这个我们很容易分析出插值基函数$l_i(x)$有零点$x_i$，其他的均为非零点，那么我们假设插值基函数为：

$$
l_i(x) = C\prod_{k=0,k\neq i}^n (x-x_k)
$$

同时因为$l_i(x_i)=1$可以继续确定常系数

$$
C = \frac{1}{\prod_{k=0,k\neq i}^n (x_i-x_k)}
$$

因此我们得到了我们的插值基函数和我们的插值拟合函数

$$
l_i(x)=\prod_{k=0,k\neq i}\frac{x-x_k}{x_i-x_k}
\\
p_n(x) = \sum_{i=0}^{n}l_i(x)y_i = \sum_{i=0}^{n}(\prod_{k=0,k\neq i}^n\frac{x-x_k}{x_i-x_k})\times y_i
$$

因此，我们可以编写出一程序，作为我们拉格朗日插值法的

``` C#
```

**更有matlab、python版本的代码在仓库中可以对照使用。仓库地址见文章开头**

#### *拉格朗日插值余项

既然是拟合，总归是有误差的，接下来我们研究一下最终的误差。对于拉格朗日插值法，误差实际上是一个阶段误差$R(x) = f(x) - p(x)$，根据之前我们推导出的拉格朗日插值函数，误差余项记为$R(x) = f(x) - p(x)$。

那么我们作一辅助函数如下

$$
\varphi(t) = f(t)-p(t)-\frac{g(t)}{g(x)}[f(x)-p(x)]\\
g(x)=\prod_{i=0}^n(x-x_i)
$$

容易发现$g^{n+1}(t) = (n+1)!$，而插值函数只有n阶，故$p^{n+1}(t) = 0$，因此我们构造的辅助函数是连续且具有n+1阶导数。当$t=x$时，则会有$\varphi(t)=0$，根据*Rolle*定理，则必有以下：

- 当$\varphi(t)$在插值区间内有n+2个互异零点时，则一阶导数至少有n+1个互异零点
- 当$\varphi^{(1)}(t)$在插值区间内有n+1个互异零点时，则$\varphi^{(2)}(t)$至少有n个互异零点

以此类推，容易知道$\varphi^{(n)}(t)$有2个零点时，则$\varphi^{(n+1)}(t)$至少有一零点，设此零点为$t=\xi$，对$\varphi(t)$求n+1次导数后，有

$$
\varphi^{(n+1)}(\xi) = f^{(n+1)}(\xi)-\frac{(b+1)!}{g(x)}[f(x)-p(x)]=0
$$

故我们插值的截断误差为$f(x)-p(x) = \frac{f^{n+1}(\xi)}{(n+1)!}\prod_{i=0}^{n}(x-x_i)$，其中$\xi$取决于我们需要预测的值。自此，我们得到了拉格朗日插值法的所有内容。

### Newton差商插值

拉格朗日插值多项式的得出并不容易，至少在计算机眼中，他是复杂的，需要计算多个n-1阶的多项式。同时，这里我们给出一个定理：**所有的插值多项式和拉格朗日插值多项式的结果应当是相同的，只是以不同的方式计算和书写。**。

#### 差商

首先我们介绍以下差商的概念，实际差商是一个很简单的东西，定义如下：假设顺序排列的节点$x_0,x_1,\dotsb,x_n$对应函数值为$f(x_0),f(x_1),\dotsb,f(x_n)$，那么一阶差商为

$$
f[x_0,x_k]=\frac{f(x_0)-f(x_k)}{x_0-x_k},(1<=k<=n)
$$

二阶差商为

$$f[x_0,x_1;x_2,x_k]=\frac{f[x_0;x_1,x_2]-f[x_0;x_1,x_k]}{x_2-x_k},(2<=k<=n)$$

那么K阶差商为：

$$f[x_0,x_1,\dotsb;x_{k-2},x_{k-1}]=\frac{f[x_0,x_1\dotsb;x_{k-2},x_{k-1}]-f[x_0,x_1\dotsb x_{k-2},x_{k}]}{x_{k-1}-x_k},(k<=n)$$

k阶差商亦可写成

$$
f[x_0,x_1,\dotsb,x_{k-1},x_{k}] = \frac{f[x_0,x_1,\dotsb,x_{k-1}]-f[x_0,x_1,\dotsb,x_{k-1},x_{k}]}{x_0-x_k}
$$

实际上就是个递推的公式，看起来似乎很复杂，但实际上自己尝试去计算的时候会发现，是一个很简单的东西，同时差商是函数的一个线性组合，这又可以说到线性代数了，我们假设组合出的多项式是一个类似坐标的玩意，而每一阶的差商实际上就是向量的基，因此通过差商，我们可以表示出多项式空间中任一多项式。

#### 牛顿差商公式

牛顿差商公式就是将我们的差商做出组合：

$$
P(x) = f[x_1]+f[x1,x2](x-x_1)+f[x_1,x_2,x_3](x-x_1)(x-x_2)+\dotsb+f[x_1\dotsb x_n](x-x_1)\dotsb (x-x_{n-1})
$$

随便给出几个插值采样点，进行计算拉格朗日和牛顿插值公式，我们在计算出各阶差商以后，会发现最终得到的插值多项式和拉格朗日多项式是一致的。那我们为什么还需要多此一举引入牛顿法进行插值而不是直接使用拉格朗日插值呢？

答案很简单，拉格朗日法在构建多项式时，我们必须先知道采样点的数量，如果后续有了新的采样点，我们就需要重新计算整个多项式，这是对于性能浪费极大的。如果采用牛顿法，那么在有新的采样点时，我们只需要多计算一次差商（因为之前的差商已经计算好），可以很容易的将新的点加入我们的多项式中。

牛顿法的代码如下（更多代码见仓库）
```C#

```

#### 插值余项

实际上，牛顿法因为得到的结果和拉格朗日插值一样，他们的误差也应该是一样的，不过既然我们选择了不同的计算方法，那么误差也可以使用新的手段进行计算。如果我们把我们的插值点看作一固定点，带入我m



### 高次插值的Runge(龙格)现象

在多项式插值以及基于多项式插值的拉格朗日插值方法和含有高次幂的牛顿插值中，我们提到过龙格现象，那么什么是龙格现象呢？首先我们先提出这样一个问题，当我们在拉格朗日多项式之中提高项数和多项式的次数，是否可以提高我们数据的精度？这个答案是否定的，我们需要减少误差，也就是说针对任意的$\epsilon>0$，总是存在正整数N，当n大于N时，所有区间内的$x$满足:

$$
f(x)-p_n(x)<\epsilon
\Leftrightarrow
\frac{f^{n+1}(\xi)}{(n+1)!}\prod_{i=0}^{n}(x-x_i)<\epsilon
$$

我们可以看到，我们的误差，随着n的增大，(n+1)!逐渐趋于无穷，而后向的乘法，并不会增大太多会变小太多，因此误差很大程度取决于n+1阶导数的范围。对于类似$sinx,e^x$，这类导数的值域范围恒定的函数，误差会随着n的增加逐步趋于0。但是如果对于某些函数而言，随着项数次数增加，误差反而会变大。龙格现象是一种出现在多项式次数很高是，在区间端点出现拟合曲线剧烈振荡的一种现象。下面通过一个例子来进行说明。

假设给定$f(x) = \frac{1}{x^2+1},x\in [-5,5]$，等距离取5，10个点，构建多项式拟合，观察图像。

![Runge](https://images.cnblogs.com/cnblogs_com/WarrenRyan/2103051/o_220921092608_untitled.jpg)

我们可以很清楚的发现，当靠近端点的时候。拟合曲线出现了剧烈的波动，误差到了一个不太可以接受的程度。并且次数越高的时候，抖动出现的更频繁、更剧烈。龙格现象的出现是由于插值节点是等距所造成的。同时，针对导函数不稳定的函数而言，盲目增加插值节点数列，则更加容易出现龙格现象。

一般而言，为了避免龙格现象，我们可以有以下的手段：
- 避免使用高次的插值多项式，一般而言，即使为了提高插值精度，也尽可能保证$n<7$。
- 分段进行插值，在每一小段使用一次插值，从而降低阶数。
- 对于性态不稳定的函数，选用其他插值手段，如Hermite插值等。

### Aitken插值

### 分段插值法

### Hermite插值

### 切比雪夫插值法

## 插值的误差分析

## 曲线拟合法

### 直线拟合

### 展开式拟合

### 指对数拟合

### 三次样条

### *贝塞尔样条

## 习题

## Reference

> 《数值分析》（原书第二版） —— Timothy Sauer
>
> 《数值计算方法》（清华大学出版社） —— 吕同富等

## About Me

<p id="PSignature" style="padding-top: 10px; padding-right: 10px; padding-bottom: 10px; padding-left: 60px; background: url("https://www.cnblogs.com/images/cnblogs_com/ECJTUACM-873284962/1318325/o_o_122329534672560.png") #e5f1f4 no-repeat 1% 50%; font-family: 微软雅黑; font-size: 12px; border: #e0e0e0 1px dashed"> <br>
        作　　者：<strong><span style="font-size: 12px; color: red"><a href="https://www.cnblogs.com/WarrenRyan/" target="_blank">WarrenRyan</a></span></strong>
        <br>
        出　　处：<a href="https://www.cnblogs.com/WarrenRyan/" target="_blank">https://www.cnblogs.com/WarrenRyan/</a>
        <br>
        本文对应视频：<a href="" target="_blank">BiliBili(待重录)</a>
        <br>
        关于作者：热爱数学、热爱机器学习，喜欢弹钢琴的不知名小菜鸡。
        <br>
        版权声明：本文版权归作者所有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文链接。若需商用，则必须联系作者获得授权。
        <br>
        特此声明：所有评论和私信都会在第一时间回复。也欢迎园子的大大们指正错误，共同进步。或者<a href="http://msg.cnblogs.com/msg/send/WarrenRyan">直接私信</a>我
        <br>
        声援博主：如果您觉得文章对您有帮助，可以点击文章右下角<strong><span style="color: #ff0000; font-size: 18pt">【<a id="post-up">推荐</a>】</span></strong>一下。您的鼓励是作者坚持原创和持续写作的最大动力！
        <br>
        <br>
        <br>
        博主一些其他平台：
        <br>
        <strong><a>微信公众号：寤言不寐</a></strong>
        <br>
        <strong><a href="https://space.bilibili.com/33311288" target="_blank">BiBili——小陈的学习记录</a></strong>
        <br>
        <strong><a href="https://github.com/StevenEco" target="_blank">Github——StevenEco</a></strong>
        <br>
        <strong><a href="https://space.bilibili.com/667199655" target="_blank">BiBili——记录学习的小陈（计算机考研纪实）</a></strong>
        <br>
        <strong><a href="https://juejin.cn/user/3756401007016173" target="_blank">掘金——小陈的学习记录</a></strong>
        <br>
        <strong><a href="https://space.bilibili.com/33311288" target="_blank">知乎——小陈的学习记录</a></strong>
        <br>
    </p>
<br/>
<div>
<div class="github-card" data-github="StevenEco" data-width="350" data-height="150" data-theme="default"></div>
<div class="github-card" data-github="StevenEco/MachineLearning-Math" data-width="350" data-height="150" data-theme="default"></div>
</div>

## 联系方式

`<a style="font-family: 微软雅黑; font-size: 18px;" href="mailto:cxtionch@gmail.com">`电子邮件：cxtionch@live.com`</a>`
`<br/>`
`<br/>`

<p style="font-family: 微软雅黑; font-size: 18px;">社交媒体联系二维码：</p>
<img style=" width: 100%" src="https://images.cnblogs.com/cnblogs_com/WarrenRyan/2090249/o_220106070541_%E4%B8%AA%E4%BA%BA%E4%BF%A1%E6%81%AF%E6%A0%8F.jpg"/>
